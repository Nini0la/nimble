{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data\n",
    "\n",
    "### Preparing interstate traffic data for machine learning\n",
    "\n",
    "The goal here is to address several issues present in the\n",
    "`'Metro_Interstate_Traffic_Volume.csv'` dataset to make it suitable for\n",
    "supervised learning. Each point in this dataset represents a point in\n",
    "time where 9 features are recorded. The features are variables which may\n",
    "affect the traffic volume on an interstate highway and the current\n",
    "traffic volume. A new point is recorded each time a change occurs in one\n",
    "of the weather forecast features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import nimble\n",
    "\n",
    "traffic = nimble.data('Matrix', 'Metro_Interstate_Traffic_Volume.csv',\n",
    "                      featureNames=True)\n",
    "# kwargs for use with .show to optimize printed output for objects\n",
    "showKwargs = {'includeObjectName': False, 'maxHeight': 9, 'maxWidth': 120}\n",
    "traffic.show(\"Raw traffic data\", **showKwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data contains 48,204 points and 9 features, but some points and features\n",
    "will need to be addressed before machine learning algorithms can be applied\n",
    "to this data. The machine learning algorithms we plan to use require numeric\n",
    "data and can be sensitive to outliers. Running `featureReport` can provide\n",
    "a good starting point for cleaning the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(traffic.featureReport())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics could not be calculated for all features, indicating some are non-numeric. The statistics for the numeric features also indicate that some outlier values may be present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning numeric data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 Kelvin in `temp` and 9831.3 mm in `rain_1h` indicate some outliers exist in\n",
    "these features. Let's extract those values to decide how to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlierIdentifier(pt):\n",
    "    if pt['temp'] == 0 or pt['rain_1h'] == 9831.3:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "outliers = traffic.points.extract(outlierIdentifier)\n",
    "\n",
    "print(traffic[:, ['temp', 'rain_1h']].featureReport())\n",
    "print('Number of points with outliers:', len(outliers.points))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After extracting those values, our `featureReport` statistics look much\n",
    "more reasonable for those features. We can assume the 11 extracted points\n",
    "contain recording errors so we will ignore `outliers` and continue with\n",
    "the 48,193 points still remaining in `traffic`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning non-numeric data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values in the `date_time` feature are strings, but we can parse each\n",
    "string to generate five new numeric features to replace this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dateTimeSplit(value):\n",
    "    dt = datetime.strptime(value, \"%Y-%m-%d %H:%M:%S\")\n",
    "    return [dt.year, dt.month, dt.day, dt.hour, dt.weekday()]\n",
    "\n",
    "traffic.features.splitByParsing('date_time', dateTimeSplit,\n",
    "                                ['year', 'month', 'day', 'hour', 'weekday'])\n",
    "\n",
    "traffic.show('New parsed features in traffic data', **showKwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `holiday` feature contains a holiday name string for the first point of\n",
    "each holiday, all other values are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplePts = slice(1369,1374)\n",
    "dateFts = ['holiday', 'year', 'month', 'day', 'hour']\n",
    "print(traffic[samplePts, dateFts])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will transform the `holiday` feature to a numeric feature by writing a\n",
    "function that assigns each point a new binary value in the `holiday` feature.\n",
    "TODO using 1/0 for now until True/False can be loaded from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentHoliday = {'date': None}\n",
    "def holidayToBinary(point):\n",
    "    filledPt = []\n",
    "    dateTuple = (point['year'], point['month'], point['day'])\n",
    "    if isinstance(point['holiday'], str):\n",
    "        currentHoliday['date'] = dateTuple\n",
    "    if currentHoliday['date'] == dateTuple:\n",
    "        filledPt.append(1)\n",
    "    else:\n",
    "        filledPt.append(0)\n",
    "        currentHoliday['date'] = None\n",
    "\n",
    "    filledPt.extend(point[1:])\n",
    "\n",
    "    return filledPt\n",
    "\n",
    "traffic.points.transform(holidayToBinary)\n",
    "print(traffic[samplePts, dateFts])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `weather_main` and `weather_description` features are very similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherFts = ['weather_main', 'weather_description']\n",
    "print(traffic[samplePts, weatherFts])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While `weather_description` is more detailed, many of its unique values\n",
    "represent a very small proportion of the data. So, we will utilize the more\n",
    "general `weather_main` and remove `weather_description`. To make the string\n",
    "values in `weather_main` suitable for machine learning, we will represent\n",
    "each of the 11 unique values as 11 new binary features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic.features.delete('weather_description')\n",
    "newCols = traffic.replaceFeatureWithBinaryFeatures('weather_main')\n",
    "print(traffic[samplePts, newCols[:3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset is now ready for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic.show('Cleaned traffic data', **showKwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing to a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that we can load the cleaned data for our supervised learning example, we\n",
    "will write it to a new csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic.writeFile('Metro_Interstate_Traffic_Volume_Cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reference:**  \n",
    "Dua, D. and Graff, C. (2019).  \n",
    "UCI Machine Learning Repository http://archive.ics.uci.edu/ml.  \n",
    "Irvine, CA: University of California, School of Information and Computer Science.\n",
    "\n",
    "**Dataset Link:**  \n",
    "https://archive.ics.uci.edu/ml/datasets/Metro+Interstate+Traffic+Volume"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SW36",
   "language": "python",
   "name": "sw36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
