{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data\n",
    "\n",
    "### Preparing interstate traffic data for machine learning\n",
    "\n",
    "The goal here is to address several issues present in the\n",
    "`Metro_Interstate_Traffic_Volume.csv` dataset to make it suitable for\n",
    "supervised machine learning (i.e., predicting one of the columns in the\n",
    "data using other columns). Each data point in this dataset represents a\n",
    "moment in time where 9 features are recorded. The features are variables\n",
    "which may affect the traffic volume on an interstate highway as well as\n",
    "the current traffic volume. A new data point is recorded each time a\n",
    "change occurs in one of the weather forecast features.\n",
    "\n",
    "In this example we will learn about:\n",
    "\n",
    "* [Loading and displaying data](#Getting-started)\n",
    "* [Cleaning numeric data](#Cleaning-numeric-data)\n",
    "* [Cleaning non-numeric data](#Cleaning-non-numeric-data)\n",
    "* [Writing data to a file](#Writing-to-a-file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started \n",
    "\n",
    "We first use `nimble.fetchFile` to retrieve our dataset. This will return\n",
    "the path to our dataset, downloading it from the web if it is not already\n",
    "available locally. Nimble has built in a shorthand for datasets in the\n",
    "[UCI repository](https://archive.ics.uci.edu/ml) that we use below. The\n",
    "second argument for `nimble.data` (`source`) can be a regular python data\n",
    "object, a path to a file, an open file, or URL pointing to the location on a\n",
    "website where the data resides. Here, we use the path returned by\n",
    "`nimble.fetchFile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import nimble\n",
    "\n",
    "path = nimble.fetchFile('uci::Metro Interstate Traffic Volume')\n",
    "traffic = nimble.data(path, name='Metro Interstate Traffic Volume',\n",
    "                      returnType=\"Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `show` method provides more flexibility for the printed output than\n",
    "using `print` or `repr`. It prints a description, the `name` and `shape` of\n",
    "the object and the object data (truncating if necessary) given the\n",
    "parameters. The `maxWidth` and `maxHeight` parameters control the number of\n",
    "characters printed horizontally and vertically, respectively. By default\n",
    "these are set dynamically based on the terminal size, but more or less of\n",
    "the data can be displayed by setting them manually. To preview our data, we\n",
    "will limit the output to 16 lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic.show(\"Raw traffic data\", maxHeight=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The machine learning algorithms we plan to use require numeric data and can\n",
    "be sensitive to outliers. Our data contains 48,204 points and 9 features,\n",
    "but some points and features will require cleaning before these machine\n",
    "learning algorithms can be applied to the data. The default\n",
    "`features.report` contains 10 statistics, but we will limit it to the\n",
    "following four to help identify non-numeric data, missing data and outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = ['mode', 'minimum', 'maximum', 'count']\n",
    "report = traffic.features.report(stats)\n",
    "report.show(\"Feature statistics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics could not be calculated for all features, indicating some are\n",
    "non-numeric. 0 Kelvin in `temp` and 9831.3 mm in `rain_1h` are also possible\n",
    "recording errors so we will also perform cleaning on some numeric features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning numeric data \n",
    "\n",
    "Let's extract (i.e., separate from the rest of the data) any rows with the\n",
    "value 0 in `temp` or 9831.3 in `rain_1h` since they seem very unlikely to be\n",
    "accurate, then we can reevaluate the statistics without those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def badPointIdentifier(pt):\n",
    "    return pt['temp'] == 0 or pt['rain_1h'] == 9831.3\n",
    "\n",
    "extracted = traffic.points.extract(badPointIdentifier)\n",
    "\n",
    "fixedReport = traffic.features.report(stats)\n",
    "fixedReport[['temp', 'rain_1h'], :].show(\"Modified feature report\")\n",
    "print('Number of points with errors:', len(extracted.points))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After extracting those values, our `features.report` statistics look much\n",
    "more reasonable for those features. Since the values for those \"bad\" data\n",
    "points were implausible, we can assume that the 11 extracted points contain\n",
    "recording errors so we will ignore `extracted` and continue with the 48,193\n",
    "points still remaining in `traffic`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning non-numeric data \n",
    "\n",
    "The values in the `date_time` feature are strings, so we will parse each\n",
    "string to generate five new numeric features ('year', 'month', 'day',\n",
    "'hour', 'weekday') to replace this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dateTimeSplitter(value):\n",
    "    dt = datetime.strptime(value, \"%Y-%m-%d %H:%M:%S\")\n",
    "    return [dt.year, dt.month, dt.day, dt.hour, dt.weekday()]\n",
    "\n",
    "traffic.features.splitByParsing('date_time', dateTimeSplitter,\n",
    "                                ['year', 'month', 'day', 'hour', 'weekday'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at our data again after splitting a single feature\n",
    "of text into 5 numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic.show('New parsed features in traffic data', maxHeight=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `holiday` feature is extremely idiosyncratic, so it will require a\n",
    "complex function to transform. Since this case this unique to this dataset,\n",
    "we won't dig into the details but Nimble can definitely handle complex cases\n",
    "like this one. The purpose of the function is to create a binary feature\n",
    "that identifies the points in the data that occur on a holiday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidayIndex = traffic.features.getIndex('holiday')\n",
    "currentHoliday = {'date': None}\n",
    "def holidayToBinary(point):\n",
    "    newPt = list(point)\n",
    "    dateTuple = (point['year'], point['month'], point['day'])\n",
    "    if isinstance(point['holiday'], str):\n",
    "        currentHoliday['date'] = dateTuple\n",
    "    if currentHoliday['date'] == dateTuple:\n",
    "        newPt[holidayIndex] = True\n",
    "    else:\n",
    "        newPt[holidayIndex] = False\n",
    "\n",
    "    return newPt\n",
    "\n",
    "pointsWithHoliday = slice(1368, 1372)\n",
    "dateInfoFeatures = ['holiday', 'year', 'month', 'day', 'hour']\n",
    "traffic.points.transform(holidayToBinary)\n",
    "sample = traffic[pointsWithHoliday, dateInfoFeatures]\n",
    "sample.show('Data sample with converted holiday feature', maxHeight=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two features related to categorizing the weather conditions. We saw\n",
    "in our first look at the data that the `weather_description` feature is more\n",
    "detailed than the `weather_main` feature. \"Clouds\" in the `weather_main`\n",
    "feature could be \"scattered clouds\", \"broken clouds\" or \"overcast clouds\" in\n",
    "`weather_description`. Since these features are very similar, we will use\n",
    "only one of them. The `weather_main` feature provides a good general idea of\n",
    "the current weather so let's delete `weather_description` from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic.features.delete('weather_description')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the string values in `weather_main` suitable for machine learning,\n",
    "we will represent each of the 11 unique values contained in this column as\n",
    "11 new binary features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newCols = traffic.replaceFeatureWithBinaryFeatures('weather_main')\n",
    "sampleFts = ['weather_main=Clouds', 'weather_main=Clear', 'weather_main=Mist']\n",
    "traffic[pointsWithHoliday, sampleFts].show('Sample of binary weather features',\n",
    "                                           maxHeight=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have removed any bad points and transformed all of our data to\n",
    "numeric values, our dataset is ready for machine learning. We will be using\n",
    "this data to predict the `traffic_volume` feature from the other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic.show('Cleaned traffic data', maxHeight=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing to a file \n",
    "\n",
    "We'd like to be able to load the cleaned data for our Supervised Learning\n",
    "example any time we want, so we will write it to a new csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic.save('Metro_Interstate_Traffic_Volume_Cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References:**\n",
    "\n",
    "Dua, D. and Graff, C. (2019).\n",
    "UCI Machine Learning Repository [http://archive.ics.uci.edu/ml].\n",
    "Irvine, CA: University of California, School of Information and Computer Science.\n",
    "\n",
    "Link:\n",
    "https://archive.ics.uci.edu/ml/datasets/Metro+Interstate+Traffic+Volume"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}