{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning\n",
    "\n",
    "### Training on interstate traffic data to make predictions about the future\n",
    "\n",
    "In this example, we will use two datasets that contain data on\n",
    "interstate traffic volumes and features that may contribute to changes\n",
    "in traffic volume. `Metro_Interstate_Traffic_Volume_Cleaned.csv`, was\n",
    "generated in our Cleaning Data example and is the cleaned data we will\n",
    "use to build our supervised learning models.\n",
    "`Metro_Interstate_Traffic_Volume_Predict.csv`, contains fictional\n",
    "\"forecast\" data that we will use to simulate making traffic volume\n",
    "predictions using our supervised machine learning model.\n",
    "\n",
    "In this example we will learn about:\n",
    "\n",
    "* [Testing machine learning algorithms](#Test-five-different-machine-learning-algorithms)\n",
    "* [Hyperparameter tuning](#Improve-performance-by-tuning-hyperparameters)\n",
    "* [Nimble's TraineLearner class](#Improve-performance-by-tuning-hyperparameters)\n",
    "* [Applying a learner to new data](#Applying-our-learner)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nimble\n",
    "\n",
    "bucket = 'https://storage.googleapis.com/nimble/datasets/'\n",
    "traffic = nimble.data(bucket + 'Metro_Interstate_Traffic_Volume_Cleaned.csv',\n",
    "                      returnType=\"Matrix\")\n",
    "forecast = nimble.data(bucket + 'Metro_Interstate_Traffic_Volume_Predict.csv',\n",
    "                       returnType=\"Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test five different machine learning algorithms \n",
    "\n",
    "We\u2019ll divide our `traffic` data into training and testing sets. The test\n",
    "set (used to measure the out-of-sample performance) will contain 25% of our\n",
    "data and the remaining 75% will be used to train each machine learning\n",
    "algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testFraction = 0.25\n",
    "yFeature = 'traffic_volume'\n",
    "trainX, trainY, testX, testY = traffic.trainAndTestSets(testFraction, yFeature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we will use algorithms from the\n",
    "[Sci-kit Learn](https://scikit-learn.org/) package so it must be installed\n",
    "in the current environment. To check if Nimble has access to Sci-kit Learn\n",
    "in your environment, you can use `nimble.showAvailablePackages`.\n",
    "Additionally, we can see a list of all of the learners available to Nimble\n",
    "by using `nimble.showLearnerNames`. Uncomment the lines below if you would\n",
    "like to see the available packages and learners in your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nimble.showAvailablePackages()\n",
    "# nimble.showLearnerNames()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nimble's training functions only need the package name and learner name to\n",
    "be identified. There is no need to recall, for example, that\n",
    "`LinearRegression` is in `sklearn.linear_model` or `KNeighborsRegressor` is\n",
    "in `sklearn.neighbors`, all Nimble requires are the strings\n",
    "'sklearn.LinearRegression' and 'sklearn.KNeighborsRegressor', respectively.\n",
    "Using `nimble.trainAndTest`, we will quickly test the performance of five\n",
    "different regression algorithms (initially, we'll use default arguments to\n",
    "keep things simple). We can then analyze the performance by comparing each\n",
    "learning algorithm's root mean square error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learners = ['sklearn.LinearRegression', 'sklearn.Ridge', 'sklearn.Lasso',\n",
    "            'sklearn.KNeighborsRegressor', 'sklearn.GradientBoostingRegressor']\n",
    "rootMeanSquareError = nimble.calculate.rootMeanSquareError\n",
    "for learner in learners:\n",
    "    performance = nimble.trainAndTest(learner, rootMeanSquareError, trainX,\n",
    "                                      trainY, testX, testY)\n",
    "    print(learner, 'error:', performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`'sklearn.KNeighborsRegressor'` and `'sklearn.GradientBoostingRegressor'`\n",
    "had better performance for predicting traffic volume with this data than the\n",
    "linear regression based learners, so let's focus on optimizing those two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve performance by tuning hyperparameters \n",
    "\n",
    "The default arguments are unlikely to yield the best performance, so now we\n",
    "will adjust some parameter values for our two best learners. These\n",
    "adjustments can be made through `arguments` as a python `dict` or as keyword\n",
    "arguments. If we need more information about a learner's parameters, we can\n",
    "use `nimble.learnerParameters` and `nimble.learnerParameterDefaults`. Let's\n",
    "try it for KNeighborsRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nimble.showLearnerParameters('sklearn.KNeighborsRegressor')\n",
    "nimble.showLearnerParameterDefaults('sklearn.KNeighborsRegressor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, we can test multiple values for the same parameter\n",
    "by using the `nimble.Tune` object. The presence of `nimble.Tune` will\n",
    "trigger hyperparameter tuning. By default, this tunes the arguments\n",
    "consecutively (optimizing one argument at a time while holding the others\n",
    "constant) and uses 5-fold cross-validation. This can be modified by\n",
    "providing a `Tuning` object to the `tuning` parameter. The tuning will find\n",
    "the argument combination with the best average `performanceFunction` result\n",
    "and return the `TrainedLearner` using the best arguments.\n",
    "\n",
    "For KNeighborsRegressor, we will use `nimble.Tune` to try 3, 5, and 7 for\n",
    "the number of nearest neighbors and for `GradientBoostingRegressor` we will\n",
    "try different learning rate values. The `Tuning` object defines a method for\n",
    "selecting each argument set and how each argument set will be validated.\n",
    "Below, we will use the default \"consecutive\" method but instead of the\n",
    "default \"cross validation\", we will hold out a random 20% of our training\n",
    "data for validation. For details on all tuning options, see the `Tuning`\n",
    "documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning = nimble.Tuning(validation=0.2, performanceFunction=rootMeanSquareError)\n",
    "# some interfaces have alias options for the package name\n",
    "# below we use the alias 'skl' for the 'sklearn' package.\n",
    "knnTL = nimble.train('skl.KNeighborsRegressor', trainX, trainY,\n",
    "                     arguments={'n_neighbors': nimble.Tune([3, 5, 7])},\n",
    "                     tuning=tuning)\n",
    "gbTL = nimble.train('skl.GradientBoostingRegressor', trainX, trainY,\n",
    "                    learning_rate=nimble.Tune([0.01, 0.1, 1]),\n",
    "                    tuning=tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `nimble.train` function returns a `TrainedLearner`. With a\n",
    "`TrainedLearner` we can `apply` (make predictions on a test set), `test`\n",
    "(measure the performance on a test set with known labels) and it provides\n",
    "many other additional methods and attributes. The `knnTL` object was trained\n",
    "with the `n_neighbors` value that performed best during validation.\n",
    "When hyperparameter tuning occured, `TrainedLearner.tuning` provides access\n",
    "to the tuning results. The `allResults` and `allArguments` properties are\n",
    "sorted from best to worst. Let's see how each `knnTL` argument performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result, args in zip(knnTL.tuning.allResults, knnTL.tuning.allArguments):\n",
    "    print(result, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly `gbTL` was trained with the best of our three possible learning\n",
    "rates. Instead of seeing all the results, let's just see the best argument\n",
    "and best result this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gbTL.tuning.bestResult, gbTL.tuning.bestArguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`knnTL` found `n_neighbors` of 5 to be the best setting.  This is the same\n",
    "as the default value so we already know how it performs on our testing data.\n",
    "However, `gbTL` found `learning_rate` of 1 outperformed the default, 0.1.\n",
    "Let's see how it performs on our testing (out-of-sample) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbPerf = gbTL.test(rootMeanSquareError, testX, testY) \n",
    "print('sklearn.GradientBoostingRegressor', 'learning_rate=1', 'error', gbPerf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying our learner \n",
    "\n",
    "We see a further improvement in the performance so the\n",
    "GradientBoostingRegressor with a learning rate of 1 is our best model. Now\n",
    "we will apply our `gbTL` trained learner to our `forecast` dataset to\n",
    "predict traffic volumes for a future day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedTraffic = gbTL.apply(forecast)\n",
    "predictedTraffic.features.setName(0, 'volume')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before printing, we will append the `hour` feature from `forecasts` to get\n",
    "a better visual of the traffic throughout the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedTraffic.features.append(forecast.features['hour'])\n",
    "predictedTraffic.show('Traffic Volume Predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our forecasted data, our learner is predicting heavier traffic\n",
    "volumes between 6 am and 6 pm with peak congestion expected around the 7 am\n",
    "hour for the morning commute and the 4 pm hour for the afternoon commute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reference:**\n",
    "\n",
    "Dua, D. and Graff, C. (2019).\n",
    "UCI Machine Learning Repository [http://archive.ics.uci.edu/ml].\n",
    "Irvine, CA: University of California, School of Information and Computer Science.\n",
    "\n",
    "Link to original dataset:\n",
    "https://archive.ics.uci.edu/ml/datasets/Metro+Interstate+Traffic+Volume"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}